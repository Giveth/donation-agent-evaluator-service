# ===========================================
# SERVER CONFIGURATION
# ===========================================

# Port for the NestJS application to run on
PORT=3000

# Node environment (development, production, test)
NODE_ENV=development

# ===========================================
# GIVETH BACKEND API CONFIGURATION
# ===========================================

# Base URL for the main Giveth backend API
GIVETH_API_URL=https://api.giveth.io

# API endpoints for fetching cause and project data
GIVETH_API_CAUSE_ENDPOINT=/api/v1/causes
GIVETH_API_PROJECT_ENDPOINT=/api/v1/projects

# Authentication for Giveth backend (if required)
# GIVETH_API_KEY=your_giveth_api_key_here
# GIVETH_API_SECRET=your_giveth_api_secret_here

# ===========================================
# DATABASE CONFIGURATION
# ===========================================

# PostgreSQL database connection string
DATABASE_URL=postgresql://donation_user:donation_pass@localhost:5432/donation_evaluator

# Individual database connection parameters (alternative to DATABASE_URL)
DB_HOST=localhost
DB_PORT=5432
DB_USER=donation_user
DB_PASSWORD=donation_pass
DB_NAME=donation_evaluator

# Database connection pool settings
DATABASE_POOL_SIZE=20
DATABASE_CONNECTION_TIMEOUT=30000

# ===========================================
# EXTERNAL API INTEGRATIONS
# ===========================================

# Twitter Authentication (Method 1: Cookies - Preferred)
TWITTER_COOKIES='[{"name":"auth_token","value":"your_auth_token_here"}]'

# Twitter Authentication (Method 2: Credentials - Fallback)
TWITTER_USERNAME=your_twitter_username
TWITTER_PASSWORD=your_twitter_password
TWITTER_EMAIL=your_twitter_email

# Twitter Rate Limiting Configuration
TWITTER_MIN_DELAY_MS=3000
TWITTER_MAX_DELAY_MS=8000
TWITTER_MAX_RETRIES=3
TWITTER_BASE_RETRY_DELAY_MS=5000

# OpenRouter API key for LLM integration (provides access to multiple LLM providers)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# LLM model name for OpenRouter (default: google/gemini-2.5-flash-preview)
# Other options: google/gemini-2.0-flash-001, openai/gpt-4o, anthropic/claude-3-sonnet, etc.
LLM_MODEL_NAME=google/gemini-2.5-flash-preview

# Optional: OpenRouter site URL and title for rankings (if desired)
# OPENROUTER_SITE_URL=https://your-site.com
# OPENROUTER_SITE_NAME=Your App Name

# ===========================================
# CACHING CONFIGURATION
# ===========================================

# Default cache TTL in seconds (3600 = 1 hour)
CACHE_TTL_DEFAULT=3600

# Cache TTL for social media data in seconds (21600 = 6 hours)
CACHE_TTL_SOCIAL_MEDIA=21600

# Cache TTL for LLM responses in seconds (43200 = 12 hours)
CACHE_TTL_LLM_RESPONSES=43200

# Cache TTL for project data in seconds (1800 = 30 minutes)
CACHE_TTL_PROJECT_DATA=1800

# ===========================================
# SOCIAL MEDIA CONFIGURATION
# ===========================================

# Maximum number of tweets to fetch per project
MAX_TWEETS_PER_PROJECT=10

# Maximum number of Farcaster casts to fetch per project
MAX_CASTS_PER_PROJECT=10

# Social media data lookback period in days
SOCIAL_MEDIA_LOOKBACK_DAYS=90

# ===========================================
# SCORING CONFIGURATION
# ===========================================

# Project Information and Update Quality weight (0-100)
SCORE_WEIGHT_PROJECT_QUALITY=20

# Update recency weight (0-100)
SCORE_WEIGHT_UPDATE_RECENCY=10

# Social media content quality weight (0-100)
SCORE_WEIGHT_SOCIAL_QUALITY=20

# Social media recency weight (0-100)
SCORE_WEIGHT_SOCIAL_RECENCY=5

# Social media frequency weight (0-100)
SCORE_WEIGHT_SOCIAL_FREQUENCY=5

# Relevance to cause weight (0-100)
SCORE_WEIGHT_RELEVANCE=20

# Existing quality score weight (0-100)
SCORE_WEIGHT_EXISTING_QUALITY=10

# GIVpower rank weight (0-100)
SCORE_WEIGHT_GIVPOWER_RANK=10

# ===========================================
# SCORING SCALES CONFIGURATION
# ===========================================

# Update recency scoring thresholds (days)
RECENCY_SCALE_EXCELLENT_DAYS=7
RECENCY_SCALE_GOOD_DAYS=30
RECENCY_SCALE_FAIR_DAYS=60
RECENCY_SCALE_POOR_DAYS=90

# Social media recency scoring thresholds (days)
SOCIAL_RECENCY_SCALE_EXCELLENT_DAYS=3
SOCIAL_RECENCY_SCALE_GOOD_DAYS=7
SOCIAL_RECENCY_SCALE_FAIR_DAYS=30

# Social media frequency scoring thresholds (post count in 90 days)
SOCIAL_FREQUENCY_SCALE_EXCELLENT_POSTS=15
SOCIAL_FREQUENCY_SCALE_GOOD_POSTS=10
SOCIAL_FREQUENCY_SCALE_FAIR_POSTS=5
SOCIAL_FREQUENCY_SCALE_POOR_POSTS=1

# ===========================================
# LLM CONFIGURATION
# ===========================================

# LLM request timeout in milliseconds
LLM_TIMEOUT=60000

# Maximum tokens for LLM responses
LLM_MAX_TOKENS=1000

# LLM temperature for randomness (0.0-2.0, lower = more deterministic)
LLM_TEMPERATURE=0.3

# Maximum retries for LLM API calls
LLM_RETRY_ATTEMPTS=3

# ===========================================
# EXTERNAL API TIMEOUTS & RETRY CONFIGURATION
# ===========================================

# HTTP request timeout in milliseconds
HTTP_TIMEOUT=30000

# Number of retries for external API calls
API_RETRY_ATTEMPTS=3

# Retry delay in milliseconds (exponential backoff base)
API_RETRY_DELAY=1000

# ===========================================
# LOGGING CONFIGURATION
# ===========================================

# Log level (error, warn, info, debug, verbose)
LOG_LEVEL=info

# Enable JSON logging format (true/false)
LOG_JSON_FORMAT=false

# Log file path (optional, leave empty for console only)
LOG_FILE_PATH=

# ===========================================
# RATE LIMITING CONFIGURATION
# ===========================================

# Rate limit for evaluation requests (requests per minute)
RATE_LIMIT_EVALUATION_RPM=10

# Rate limit window in minutes
RATE_LIMIT_WINDOW_MINUTES=1

# ===========================================
# DEVELOPMENT/DEBUG CONFIGURATION
# ===========================================

# Enable debug mode (shows detailed error messages)
DEBUG_MODE=false

# Enable request/response logging
LOG_REQUESTS=false

# Mock external APIs for development (true/false)
MOCK_EXTERNAL_APIS=false